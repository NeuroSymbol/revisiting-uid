{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIIrgJP3jX9V"
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "from transformers import BertTokenizerFast, BertModel, BertForMaskedLM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import re, os\n",
    "import bisect\n",
    "import kenlm\n",
    "import mosestokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "puOKL93ipFNH",
    "outputId": "343dbcd3-d42a-4518-eee9-0c0ac2f6366f"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "install.packages('lme4')\n",
    "install.packages('MuMIn')\n",
    "install.packages('lmerTest')\n",
    "install.packages('ggplot2')\n",
    "install.packages('infotheo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LM Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262,
     "referenced_widgets": [
      "360659bccda142909965ec6e5d6b0e2f",
      "114a878aff67482a928ce41ed29ac028",
      "2eb20e4e14a44cd8be52c7adffbb0086",
      "60f907d4519047cc801eda211c19680e",
      "9f7ab2972ed74dd6b69a3d20f7b64901",
      "6d33b55928d847498bfa37b57c9f7330",
      "c126e7f5f5994baca78cfb6005363c03",
      "d8c95a40f2e04e6f8219f90062280e31",
      "4b2d902b773848b4a2be01bc3633b2f7",
      "b2cd7eb599be47158b068f28fd1b7294",
      "eccca372ba574f24bf90f1019d19cdb9",
      "6c35185ee9b24db7833393e2d83dce6e",
      "8e68b61b6e324991980ab64362a5b13b",
      "15efe74b0da049eb93d66d84f10b3092",
      "8223cacfa0814690913d5936d34b8214",
      "88f1c33ee81849ba9000282b23b7efb6",
      "f37c4b80c1ca4c46a7d4362d7472f275",
      "13cd18c98bf7491a9a27a7c3ef6aa4ae",
      "20b47415dfb34ab08ecbf7ea37619672",
      "3f7b744851d44d339f81911f9f123e5e",
      "5ee8084f887d44a6a09c48c35e9e1e4d",
      "e4b5f1da26144b2fb2cb658986b38304",
      "5f16b8940b0741fd9e4b84d9574a46ec",
      "66f6a68e1a98471595c64c64cb2184a6",
      "9ba6b8d763fd4f50912d973e4b28caf6",
      "297102f4a9a34e038d37313bbb6aace2",
      "80a0b1302cda41958c0da510d2bb0982",
      "a8a13ec26f52454295d1ef8cd51154a2",
      "466c7761b8634e95999e234cdb31cd07",
      "0ede6d1e941341c59e0691f859271da3",
      "887ed81860494f85877ca0a4a669072e",
      "f4976f17821f47bb84efb356d51fe8cc",
      "a3c6e47cf0d9474aa7e9b83786d4c859",
      "f1deda43831148c6a3fe176e4d658012",
      "973d00e6981d45b8a419e063e66b634f",
      "167e54144ee14de98628a2394e8e9b67",
      "c944a5aed5ff45a1974109645a6a2ca8",
      "878f586819f94f1db5ee4e293a483a4c",
      "662bdf8ab41647638c847dd063a9ad8c",
      "47ce7046050747ccb4dc3015677d11e8"
     ]
    },
    "id": "l1X-5O0BulIK",
    "outputId": "f60cd913-85ef-474f-e145-1d3a83a2c5f0"
   },
   "outputs": [],
   "source": [
    "STRIDE = 200\n",
    "def score_gpt(sentence):\n",
    "      with torch.no_grad():\n",
    "        all_log_probs = torch.tensor([], device=model.device)\n",
    "        offset_mapping = []\n",
    "        start_ind = 0\n",
    "\n",
    "        while True:\n",
    "            encodings = tokenizer(sentence[start_ind:], max_length=1022, truncation=True, return_offsets_mapping=True)\n",
    "            tensor_input = torch.tensor([[tokenizer.bos_token_id] + encodings['input_ids'] + [tokenizer.eos_token_id]], device=model.device)\n",
    "            output = model(tensor_input, labels=tensor_input)\n",
    "            shift_logits = output['logits'][..., :-1, :].contiguous()\n",
    "            shift_labels = tensor_input[..., 1:].contiguous()\n",
    "            log_probs = torch.nn.functional.cross_entropy(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1), reduction='none')\n",
    "            assert torch.isclose(torch.exp(sum(log_probs)/len(log_probs)),torch.exp(output['loss']))\n",
    "            offset = 0 if start_ind == 0 else STRIDE-1\n",
    "            all_log_probs = torch.cat([all_log_probs,log_probs[offset:-1]])\n",
    "            offset_mapping.extend([(i+start_ind, j+start_ind) for i,j in encodings['offset_mapping'][offset:]])\n",
    "            if encodings['offset_mapping'][-1][1] + start_ind == len(sentence):\n",
    "                break\n",
    "            start_ind += encodings['offset_mapping'][-STRIDE][1]\n",
    "        return np.asarray(all_log_probs.cpu()), offset_mapping\n",
    "\n",
    "\n",
    "def score_bert(sentence):\n",
    "    mask_id = tokenizer.convert_tokens_to_ids('[MASK]')\n",
    "    with torch.no_grad():\n",
    "        all_log_probs = []\n",
    "        offset_mapping = []\n",
    "        start_ind = 0\n",
    "        while True:\n",
    "            encodings = tokenizer(sentence[start_ind:], max_length=512, truncation=True, return_offsets_mapping=True)\n",
    "            tensor_input = torch.tensor([encodings['input_ids']], device=model.device)\n",
    "            mask_input = tensor_input.clone()\n",
    "            offset = 1 if start_ind == 0 else STRIDE\n",
    "            for i, word in enumerate(encodings['input_ids'][:-1]):\n",
    "                if i < offset:\n",
    "                    continue\n",
    "                mask_input[:,i]=mask_id\n",
    "                output = model(mask_input, labels=tensor_input)\n",
    "                log_probs = torch.nn.functional.log_softmax(output['logits'][:,i], dim=-1).squeeze(0)\n",
    "                all_log_probs.append(-log_probs[tensor_input[0,i]].item())\n",
    "                mask_input[:,i] = word\n",
    "            \n",
    "            offset_mapping.extend([(i+start_ind, j+start_ind) for i,j in encodings['offset_mapping'][offset:-1]])\n",
    "            if encodings['offset_mapping'][-2][1] + start_ind >= (len(sentence)-1):\n",
    "                break\n",
    "            start_ind += encodings['offset_mapping'][-STRIDE-1][1]\n",
    "            \n",
    "        return all_log_probs, offset_mapping\n",
    "\n",
    "\n",
    "MOSESTOKENIZER = mosestokenizer.MosesTokenizer(\"en\")\n",
    "MOSESDETOKENIZER = mosestokenizer.MosesDetokenizer(\"en\")\n",
    "def score_ngram(sentence):\n",
    "    #return strange characters back to original form\n",
    "    tokens = [MOSESDETOKENIZER([t]) for t in MOSESTOKENIZER(sentence)]\n",
    "    tokenized_sentence = \" \".join(tokens)\n",
    "    spans = []\n",
    "    word_start = 0\n",
    "    for t in tokens:\n",
    "        while sentence[word_start] != t[0]:\n",
    "            word_start += 1\n",
    "        spans.append((word_start, word_start+len(t)))\n",
    "        word_start += len(t)\n",
    "    scores = model.full_scores(tokenized_sentence, eos=False, bos=True)\n",
    "    return np.array([-s[0] for s in scores]), spans\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MODEL = \"gpt\"\n",
    "\n",
    "if MODEL == \"bert\":\n",
    "    model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "    score = score_bert\n",
    "    \n",
    "elif MODEL == \"ngram\":\n",
    "    model = kenlm.Model('wiki.arpa')\n",
    "    score = score_ngram\n",
    "    \n",
    "else:\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "    score = score_gpt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zeNipijevY1A",
    "outputId": "5d17467e-3327-40c2-f985-4844b2f1ecd6"
   },
   "outputs": [],
   "source": [
    "# Sanity check for above function\n",
    "a=['there is a book on the desk',\n",
    "                'there is a plane on the desk',\n",
    "                        'there is a books in the desk']\n",
    "scores = [score(i) for i in a]\n",
    "print([sum(s[0]) for s in scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpRxMMne7Jsg",
    "outputId": "0f895cc2-edb1-450a-edd0-24a523ce09c5"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "def string_join(x, j=''):\n",
    "    return j.join(x)\n",
    "\n",
    "def get_word_mapping(words):\n",
    "    offsets = []\n",
    "    pos = 0\n",
    "    for w in words:\n",
    "        offsets.append((pos,pos+len(w)))\n",
    "        pos += len(w) + 1\n",
    "    return offsets\n",
    "\n",
    "def string_to_log_probs(string, probs, offsets):\n",
    "    words = string.split()\n",
    "    agg_log_probs = []\n",
    "    word_mapping = get_word_mapping(words)\n",
    "    cur_prob = 0\n",
    "    cur_word_ind = 0\n",
    "    for lp, ind in zip(probs, offsets):\n",
    "        cur_prob += lp\n",
    "        start, end = ind\n",
    "        start_cur_word, end_cur_word = word_mapping[cur_word_ind]\n",
    "        if end == end_cur_word:\n",
    "            agg_log_probs.append(cur_prob)\n",
    "            cur_prob = 0\n",
    "            cur_word_ind += 1\n",
    "    return agg_log_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(sentence, n=3):\n",
    "    words = sentence.split()\n",
    "    words = [\"BOS\"]*(n-1) + words + [\"EOS\"]\n",
    "    ngrams = []\n",
    "    for i in range(len(words)-n+1):\n",
    "        ngrams.append((tuple(words[i:i+n-1]), words[i+n-1]))\n",
    "    return ngrams\n",
    "\n",
    "def normalize(root, log=True):\n",
    "    for prefix in root.keys():\n",
    "        counts = root[prefix]\n",
    "        total_counts = np.sum([counts[word] for word in counts.keys()])\n",
    "        if log:\n",
    "            root[prefix] = {k: np.log(v)- np.log(total_counts) for (k,v) in counts.items()}\n",
    "        else:\n",
    "            root[prefix] = {k: v/total_counts  for (k,v) in counts.items()}\n",
    "    return root\n",
    "\n",
    "def sampling_format(root, normalize=True):\n",
    "    for prefix in root.keys():\n",
    "        v = root[prefix]\n",
    "        words = list(v.keys())\n",
    "        counts = np.array([v[word] for word in words])\n",
    "        if normalize:\n",
    "            counts = counts/np.sum(counts)\n",
    "        root[prefix] = (words, np.log(counts))\n",
    "    return root\n",
    "\n",
    "def create_ngram_model(filename, n, outfile):\n",
    "    with open(filename, 'r') as f:\n",
    "        root = defaultdict(lambda: defaultdict(int))\n",
    "        for sentence in f:\n",
    "            if not sentence:\n",
    "                continue\n",
    "            ngrams = get_ngrams(sentence.lower().strip(), n)\n",
    "            for ngram in ngrams:\n",
    "                root[ngram[0]][ngram[1]] += 1\n",
    "        root = normalize(root, log=False)\n",
    "        pickle.dump(dict(root), open(outfile, \"wb\"))\n",
    "        return root\n",
    "\n",
    "def get_corpus_mean(filename, n=100000):\n",
    "    with open(filename, 'r') as f:\n",
    "        probs = []\n",
    "        for i, sentence in enumerate(f):\n",
    "            if i == n:\n",
    "                break\n",
    "            if sentence.isspace():\n",
    "                continue\n",
    "            probs.extend(score(sentence.strip())[0])\n",
    "        return np.mean(probs)\n",
    "n = 1\n",
    "root = create_ngram_model(\"wikitext-103/wiki.train.tokens\", 1, \"unigram.pkl\")\n",
    "#root = pickle.load(open(\"unigram.pkl\", \"rb\"))\n",
    "CORPUS_MEAN = 3.88445 #get_corpus_mean(\"wikitext-103/wiki.train.tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import log_softmax, softmax\n",
    "POWER_RANGE = np.arange(0.25, 4, 0.25)\n",
    "POWER_RANGE2 = np.arange(1, 3, 0.25)\n",
    "def power(x, y): \n",
    "    return np.mean(x**y)\n",
    "\n",
    "def ent(x):\n",
    "    l_soft = log_softmax(-x)\n",
    "    return -sum(np.exp(l_soft)*l_soft)\n",
    "\n",
    "def ent2(x):\n",
    "    return sum(np.exp(-x)*x)\n",
    "\n",
    "def r_ent(x, k=2):\n",
    "    soft = softmax(-x)\n",
    "    return 1/(1-k)*np.log(sum(soft**k))\n",
    "\n",
    "def r_ent2(x, k=2):\n",
    "    return 1/(1-k)*np.log(sum(np.exp(-x)**k))\n",
    "\n",
    "def local_diff(x):\n",
    "    d = 0\n",
    "    for i in range(len(x)-1):\n",
    "        d += abs(x[i+1]-x[i])\n",
    "    return d/len(x)\n",
    "\n",
    "def local_diff2(x):\n",
    "    d = 0\n",
    "    for i in range(len(x)-1):\n",
    "        d += (x[i+1]-x[i])**2\n",
    "    return d/len(x)\n",
    "\n",
    "def tokenize_to_sents(s):\n",
    "    sents = []\n",
    "    for sen in nltk.sent_tokenize(s):\n",
    "        #failure case of sentence tokenizer\n",
    "        if sen.split()[0] != \"',\":\n",
    "            sents.append(sen)\n",
    "        else:\n",
    "            sents[-1] += sen\n",
    "    return sents\n",
    "\n",
    "def corpus_stats(df, probs_file='', split_sens=True, wiki_mean=True, save=False):\n",
    "    stats = defaultdict(lambda: defaultdict(list))\n",
    "    try:\n",
    "        stats['log_probs'] = pickle.load(open(probs_file, \"rb\"))\n",
    "    except:\n",
    "        import itertools\n",
    "        df, df_copy = itertools.tee(df)\n",
    "        stats['log_probs'] = {i: score(s.strip()) for i,s in df_copy}\n",
    "    lang_mean = CORPUS_MEAN if wiki_mean else np.mean(np.concatenate([s[0] for s in stats['log_probs'].values()])) \n",
    "    print(\"Using language mean surprisal:\", lang_mean)\n",
    "    for i, s in df:\n",
    "      # remove leading and trailing white space\n",
    "        s = s.strip()\n",
    "        stats['split_string'][i] = s.split()\n",
    "        if split_sens:\n",
    "            lens = [len(sen.split()) for sen in tokenize_to_sents(s)]\n",
    "            assert len(s.split()) == sum(lens)\n",
    "            stats['sent_markers'][i] = np.cumsum(lens)\n",
    "            stats['agg_log_probs'][i] = np.array(string_to_log_probs(s, *stats['log_probs'][i]))\n",
    "            assert len(stats['agg_log_probs'][i]) == len(stats['split_string'][i])\n",
    "        else:\n",
    "            stats['agg_log_probs'][i] = stats['log_probs'][i][0]\n",
    "            stats['sent_markers'][i] = [len(stats['agg_log_probs'][i])] \n",
    "        \n",
    "        for j in range(len(stats['sent_markers'][i])):\n",
    "            prev = 0 if not j else stats['sent_markers'][i][j-1]\n",
    "            end = stats['sent_markers'][i][j]\n",
    "            stats['log_prob_variance'][i].append(np.var(stats['agg_log_probs'][i][prev:end]))\n",
    "            stats['log_prob_variance_lang'][i].append(np.mean((stats['agg_log_probs'][i][prev:end] - lang_mean)**2))\n",
    "            stats['log_prob_max'][i].append(np.amax(stats['agg_log_probs'][i][prev:end]))\n",
    "            stats['log_prob_mean'][i].append(np.mean(stats['agg_log_probs'][i][prev:end]))\n",
    "            stats['log_prob_ldiff'][i].append(local_diff(stats['agg_log_probs'][i][prev:end]))\n",
    "            stats['log_prob_ldiff2'][i].append(local_diff2(stats['agg_log_probs'][i][prev:end]))\n",
    "            stats['len'][i].append(end-prev)\n",
    "            \n",
    "            for p in POWER_RANGE:\n",
    "                if p < 1:\n",
    "                    func1 = lambda x: r_ent(x, p) \n",
    "                    func2 = lambda x: r_ent2(x, p)\n",
    "                elif p == 1:\n",
    "                    func1 = lambda x: 1/ent(x) if ent(x) else 0\n",
    "                    func2 = lambda x: 1/ent2(x) if ent2(x) else 0\n",
    "                else:\n",
    "                    func1 = lambda x: 1/r_ent(x, p) if r_ent(x, p) else 0\n",
    "                    func2 = lambda x: 1/r_ent2(x, p) if r_ent2(x, p) else 0\n",
    "                stats['log_prob_entropy_' + str(p)][i].append(func1(stats['agg_log_probs'][i][prev:end]))\n",
    "                stats['log_prob_entropy_n_' + str(p)][i].append(func2(stats['agg_log_probs'][i][prev:end]))\n",
    "                stats['log_prob_power_' + str(p)][i].append(power(stats['agg_log_probs'][i][prev:end], p))  \n",
    "    if save: \n",
    "        pickle.dump(stats['log_probs'], open(probs_file, \"wb\"))\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_aggregate_cols(aggregate_per_sentence, stats):\n",
    "    def add_attribute(name):\n",
    "        aggregate_per_sentence[name] = aggregate_per_sentence.apply(lambda x: stats[name][x['text_id_']][int(x['sentence_num_'])], axis=1)\n",
    "    \n",
    "    attributes = ['log_prob_mean','log_prob_max','log_prob_variance', \n",
    "                  'log_prob_variance_lang', 'log_prob_ldiff', 'log_prob_ldiff2', 'len']\n",
    "    for i in POWER_RANGE:\n",
    "        attributes.extend(['log_prob_entropy_'+str(i), 'log_prob_entropy_n_'+str(i), 'log_prob_power_'+str(i)])\n",
    "    for a in attributes:\n",
    "        add_attribute(a)\n",
    "    aggregate_per_sentence['log_prob_std'] = np.sqrt(aggregate_per_sentence['log_prob_variance'])\n",
    "    \n",
    "\n",
    "def produce_aggregate_per_sentence(main_df, stats, line_col=None):\n",
    "    aggregate_per_sentence = main_df.groupby(by=[\"WorkerId\",\"text_id\", \"sentence_num\"]).agg({\"time\":[np.sum, np.mean, np.count_nonzero], \n",
    "                                                                                                               \"word_len\":[np.sum, np.mean], \n",
    "                                                                                                               \"freq\":[np.sum, np.mean]}).reset_index()\n",
    "    aggregate_per_sentence.columns = ['_'.join(col).strip() for col in aggregate_per_sentence.columns.values]\n",
    "    if line_col:\n",
    "        aggregate_per_sentence['line_breaks'] = main_df.groupby(by=[\"WorkerId\",\"text_id\", \"sentence_num\"], as_index = False).agg({line_col: lambda x:len(np.unique(x))})[line_col]\n",
    "    add_aggregate_cols(aggregate_per_sentence, stats)\n",
    "    return aggregate_per_sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_df_columns(df, stats, rolling_vals=False):\n",
    "    df['centered_time'] = df['time'] - df.groupby(by=[\"WorkerId\"]).transform('mean')[\"time\"]\n",
    "    df['prev_word'] = df.apply(lambda x: stats['split_string'][x['text_id']][x['new_ind']-1] if x['new_ind']-1 >= 0 else '', axis=1)\n",
    "    df['log_prob'] = df.apply(lambda x: stats['agg_log_probs'][x['text_id']][x['new_ind']], axis=1)\n",
    "    df['prev_log_prob'] = df.apply(lambda x: stats['agg_log_probs'][x['text_id']][x['new_ind']-1] if x['new_ind']-1 >= 0 else 0, axis=1)\n",
    "    df['prev2_log_prob'] = df.apply(lambda x: stats['agg_log_probs'][x['text_id']][x['new_ind']-2] if x['new_ind']-2 >= 0 else 0, axis=1)\n",
    "    df['prev3_log_prob'] = df.apply(lambda x: stats['agg_log_probs'][x['text_id']][x['new_ind']-3] if x['new_ind']-3 >= 0 else 0, axis=1)\n",
    "    df['word_len'] = df.apply(lambda x: len(x['word']), axis=1)\n",
    "    df['prev_word_len'] = df.apply(lambda x: len(x['prev_word']), axis=1)\n",
    "    df['freq'] = df.apply(lambda x: root[()].get(x['word'],0), axis=1)\n",
    "    df['prev_freq'] = df.apply(lambda x: root[()].get(x['prev_word'],0), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_string_join(x, j=''):\n",
    "    s = sorted(x, key=lambda x: x[0])\n",
    "    a,b = list(zip(*s))\n",
    "    return a, j.join(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2--T130v11X7"
   },
   "outputs": [],
   "source": [
    "gpt3_probs = pd.read_csv(\"https://raw.githubusercontent.com/languageMIT/naturalstories/master/probs/all_stories_gpt3.csv\")\n",
    "# To get same indexing as stories db\n",
    "gpt3_probs[\"story\"] = gpt3_probs[\"story\"] + 1\n",
    "gpt3_probs['len'] = gpt3_probs.groupby(\"story\", sort=False)['offset'].shift(periods=-1, fill_value=0) - gpt3_probs['offset'] \n",
    "gpt3_probs['new_token'] = gpt3_probs.apply(lambda x: x['token'] if x['len'] == len(x['token']) else x['token'] + ' ', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stories_df = gpt3_probs.groupby(by=[\"story\"], sort=False).agg({\"new_token\":[string_join]}).reset_index()\n",
    "ns_stats = corpus_stats(zip(stories_df['story'], stories_df['new_token', 'string_join']), \"ns_gpt_probs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgoj--Y6fajD"
   },
   "outputs": [],
   "source": [
    "reading_times_df = pd.read_csv(\"https://raw.githubusercontent.com/languageMIT/naturalstories/master/naturalstories_RTS/processed_RTs.tsv\", sep='\\t').drop_duplicates()\n",
    "reading_times_df.rename(columns = {'RT':'time', \n",
    "                                   'item': 'text_id'}, inplace = True)\n",
    "reading_times_df['new_ind'] = reading_times_df['zone'] - 1\n",
    "reading_times_df['sentence_num'] = reading_times_df.apply(lambda x: bisect.bisect(ns_stats['sent_markers'][x['text_id']], x['new_ind']), axis=1)\n",
    "# ref token is sanity check. should be same as word\n",
    "reading_times_df['ref_token'] = reading_times_df.apply(lambda x: ns_stats['split_string'][x['text_id']][x['new_ind']], axis=1)\n",
    "add_df_columns(reading_times_df, ns_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "iEm5Q51-QCuk",
    "outputId": "8eefaea4-50e2-4340-c7cf-0076f8d5135f"
   },
   "outputs": [],
   "source": [
    "# looks like there's a small mispelling somewhere ;)\n",
    "reading_times_df[reading_times_df['word'] != reading_times_df['ref_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_agg_per_sentence = produce_aggregate_per_sentence(reading_times_df, ns_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D1KROJj_7OGC",
    "outputId": "fb19f538-9515-485f-86fd-ed88fba19ef7"
   },
   "outputs": [],
   "source": [
    "provo = pd.read_csv('provo.csv')\n",
    "provo.rename(columns = {'IA_DWELL_TIME':'time', 'Participant_ID': 'WorkerId', 'Word':'word', \n",
    "                        \"Text_ID\":\"text_id\", \"Sentence_Number\":\"sentence_num\"}, inplace = True)\n",
    "provo = provo.dropna(subset=[\"Word_Number\"])\n",
    "provo = provo.astype({\"Word_Number\": 'Int64', \"sentence_num\": 'Int64'})\n",
    "# First word isn't in dataset... Probably leads to artifically high surprisal\n",
    "provo.loc[provo.Word_Number== 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds, paragraphs = zip(*provo[['text_id','Word_Number','word']].drop_duplicates().dropna().groupby(by = ['text_id']).apply(lambda x: ordered_string_join(zip(x['Word_Number'], x['word']), ' ')))\n",
    "provo_stats = corpus_stats(enumerate(paragraphs,1), \"provo_gpt_probs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provo['new_ind'] = provo.apply(lambda x: inds[x['text_id']-1].index(x[\"Word_Number\"]), axis=1)\n",
    "provo['sentence_num'] = provo.apply(lambda x: bisect.bisect(provo_stats['sent_markers'][x['text_id']], x['new_ind']), axis=1)\n",
    "#sanity check\n",
    "provo['ref_token'] = provo.apply(lambda x: provo_stats['split_string'][x['text_id']][x['new_ind']], axis=1) \n",
    "add_df_columns(provo, provo_stats, rolling_vals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provo_agg_per_sentence = produce_aggregate_per_sentence(provo, provo_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCL Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucl = pd.read_csv('ucl/selfpacedreading.RT.txt','\\t')\n",
    "ucl.rename(columns = {'RT':'time', 'subj_nr': 'WorkerId', \n",
    "                        \"sent_nr\":\"text_id\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds, paragraphs = zip(*ucl[['text_id','word_pos','word']].drop_duplicates().dropna().groupby(by = ['text_id']).apply(lambda x: ordered_string_join(zip(x['word_pos'], x['word']), ' ')))\n",
    "ucl_stats = corpus_stats(enumerate(paragraphs,1), \"ucl_gpt_probs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucl['new_ind'] = ucl.apply(lambda x: inds[x['text_id']-1].index(x[\"word_pos\"]), axis=1)\n",
    "# ref token is sanity check. should be same as word\n",
    "ucl['ref_token'] = ucl.apply(lambda x: ucl_stats['split_string'][x['text_id']][x['new_ind']], axis=1)\n",
    "ucl['sentence_num'] = 0\n",
    "add_df_columns(ucl, ucl_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucl_agg_per_sentence = produce_aggregate_per_sentence(ucl, ucl_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCL Eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucl_eye = pd.read_csv('ucl/eyetracking.RT.txt','\\t')\n",
    "ucl_eye.rename(columns = {'RTfirstpass':'time', 'subj_nr': 'WorkerId', \n",
    "                        \"sent_nr\":\"text_id\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = ucl_eye[['text_id','word_pos','word']].drop_duplicates().dropna().groupby(by = ['text_id']).apply(lambda x: ordered_string_join(zip(x['word_pos'], x['word']), ' '))\n",
    "inds, paragraphs = zip(*joined)\n",
    "ucl_eye_stats = corpus_stats(zip(joined.index, paragraphs), \"ucl_eye_gpt_probs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_dict = {i: ind_set for i, ind_set in zip(joined.index, inds)}\n",
    "ucl_eye['new_ind'] = ucl_eye.apply(lambda x: inds_dict[x['text_id']].index(x[\"word_pos\"]), axis=1)\n",
    "ucl_eye['sentence_num'] = 0\n",
    "ucl_eye['ref_token'] = ucl_eye.apply(lambda x: ucl_eye_stats['split_string'][x['text_id']][x['new_ind']], axis=1)\n",
    "add_df_columns(ucl_eye, ucl_eye_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucl_eye_agg_per_sentence = produce_aggregate_per_sentence(ucl_eye, ucl_eye_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cola = pd.read_csv('cola_public/raw/in_domain_train.tsv','\\t', header=None, names=['ID','accept','NA','sentence'])\n",
    "cola = cola.drop(columns='NA')\n",
    "cola['text_id_'] = cola.index\n",
    "cola['sentence_num_'] = 0\n",
    "cola_stats = corpus_stats(enumerate(cola['sentence']), \"cola_gpt_probs.pkl\", split_sens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_aggregate_cols(cola, cola_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EN Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enwiki = pd.read_csv('enwiki.csv','\\t')\n",
    "enwiki.rename(columns = {'mean_rating':'accept'}, inplace = True)\n",
    "enwiki['text_id_'] = enwiki.index\n",
    "enwiki['sentence_num_'] = 0\n",
    "enwiki_stats = corpus_stats(enumerate(enwiki['text']), \"enwiki_gpt_probs.pkl\", split_sens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_aggregate_cols(enwiki, enwiki_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dundee Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_encoding(file_path, n_lines=50):\n",
    "    '''Predict a file's encoding using chardet'''\n",
    "    import chardet\n",
    "\n",
    "    # Open the file as binary data\n",
    "    with open(file_path, 'rb') as f:\n",
    "        # Join binary lines for specified number of lines\n",
    "        rawdata = b''.join([f.readline() for _ in range(n_lines)])\n",
    "\n",
    "    return chardet.detect(rawdata)['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s\\w\\d+ma2: data in fixation order\n",
    "# WNUM in eyetracking DF maps to word index in text DF\n",
    "dundeeDir = 'dundee/eye-tracking'\n",
    "fileList = [os.path.join(dundeeDir, f) for f in os.listdir(dundeeDir) if re.match(r's\\w\\d+ma2p*\\.dat', f)]\n",
    "cols = ['WorkerId', 'text_id', 'WORD','TEXT','LINE','OLEN','WLEN','XPOS','WNUM','FDUR','OBLP','WDLP','FXNO','TXFR']\n",
    "dundee = pd.DataFrame(columns = cols)\n",
    "for file in fileList:\n",
    "    temp = pd.read_csv(file, sep='\\s+', encoding='Windows-1252')\n",
    "    match = re.search(r'(s\\w)(\\d+)ma2p*\\.dat', file.split('/')[-1])\n",
    "    subjId = match.group(1)\n",
    "    text = int(match.group(2))\n",
    "    temp.insert(loc=0, column='text_id', value=text)\n",
    "    temp.insert(loc=0, column='WorkerId', value=subjId)\n",
    "    dundee = dundee.append(temp)\n",
    "dundee.rename(columns = {'FDUR':'time', 'WORD':'word', 'WNUM': 'Word_Number'}, inplace = True)\n",
    "dundee['time'] = dundee.time.astype('int64')\n",
    "dundee = dundee.reset_index().drop(columns=['index','OLEN','XPOS','OBLP','WDLP','FXNO','TXFR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dundeeDir = 'dundee/texts'\n",
    "textList = [os.path.join(dundeeDir, f) for f in os.listdir(dundeeDir) if re.match(r'tx\\d+wrdp\\.dat', f)]\n",
    "cols = ['word', 'text_id', 'screen_nr', 'line_nr', 'pos_on_line', 'serial_nr', 'initial_letter_position', 'word_len_punct', 'word_len', 'punc_code', 'n_chars_before','n_chars_after', 'Word_Number', 'local_word_freq']\n",
    "dundeeTexts = pd.DataFrame(columns = cols)\n",
    "for text in textList:\n",
    "    temp = pd.read_csv(text, sep='\\s+', names=cols, encoding='Windows-1252')\n",
    "    dundeeTexts = dundeeTexts.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds, paragraphs = zip(*dundeeTexts[['text_id','Word_Number','word']].drop_duplicates().dropna().groupby(by = ['text_id']).apply(lambda x: ordered_string_join(zip(x['Word_Number'], x['word']), ' ')))\n",
    "dundee_stats = corpus_stats(enumerate(paragraphs,1), \"dundee_gpt_probs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dundee['new_ind'] = dundee.apply(lambda x: inds[x['text_id']-1].index(x[\"Word_Number\"]), axis=1)\n",
    "dundee['sentence_num'] = dundee.apply(lambda x: bisect.bisect(dundee_stats['sent_markers'][x['text_id']], x['new_ind']), axis=1)\n",
    "dundee['ref_token'] = dundee.apply(lambda x: dundee_stats['split_string'][x['text_id']][x['new_ind']], axis=1) \n",
    "add_df_columns(dundee, dundee_stats, rolling_vals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dundee_agg_per_sentence = produce_aggregate_per_sentence(dundee, dundee_stats, line_col='LINE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qiGB0Mo3wtP9",
    "outputId": "2682d0f2-2497-4852-cbbe-a952c8d8d0d5"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(lme4)\n",
    "library(MuMIn)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = reading_times_df\n",
    "aggregate_per_sentence = ns_agg_per_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = provo\n",
    "aggregate_per_sentence = provo_agg_per_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ucl\n",
    "aggregate_per_sentence = ucl_agg_per_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ucl_eye\n",
    "aggregate_per_sentence = ucl_eye_agg_per_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dundee\n",
    "aggregate_per_sentence = dundee_agg_per_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Psychometric Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBSg34hkqDQH"
   },
   "outputs": [],
   "source": [
    "%R -i aggregate_per_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "lme_cross_val <- function(formula, df, d_var, num_folds=10, shuffle=FALSE){\n",
    "    if(shuffle){\n",
    "        df <- df[sample(nrow(df)),]\n",
    "    }\n",
    "    folds <- cut(seq(1,nrow(df)),breaks=num_folds,labels=FALSE)\n",
    "    estimates <- c()\n",
    "    for(i in 1:num_folds){\n",
    "        testIndexes <- which(folds==i,arr.ind=TRUE)\n",
    "        testData <- df[testIndexes,]\n",
    "        trainData <- df[-testIndexes,]\n",
    "        model <- lmer(formula, REML=FALSE, data=trainData)\n",
    "        sigma <- mean(residuals(model)^2)\n",
    "        estimate <- log(dnorm(testData[[d_var]], \n",
    "                              mean=predict(model, newdata=testData, allow.new.levels=TRUE), \n",
    "                              sd=sqrt(sigma)))\n",
    "        estimates <- c(estimates, estimate)\n",
    "    }\n",
    "    estimates\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3FnBG2eqOaB",
    "outputId": "f5bdd0e8-7cfc-456f-9129-5c0bb738fecb"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "set.seed(42)\n",
    "shuffled_order <- sample(nrow(aggregate_per_sentence))\n",
    "baseline <- lme_cross_val(\"time_sum ~  time_count_nonzero  + (1 | WorkerId_)\", \n",
    "                          aggregate_per_sentence[shuffled_order,],\n",
    "                         'time_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "powers_np_format <- c('1.0', '1.25', '1.5' , '1.75', '2.0', '2.25', '2.5' , '2.75', '3.0', '3.25', '3.5' , '3.75')\n",
    "labels <- seq(1, 3.75, by=0.25)\n",
    "agg_baseline <- lme_cross_val(\"time_sum ~  word_len_sum*freq_sum + time_count_nonzero + (1 | WorkerId_)\", aggregate_per_sentence[shuffled_order,], 'time_sum')\n",
    "power_func <- function(x){\n",
    "    formula <- paste0(\"time_sum ~ log_prob_power_\", x,\" :len + word_len_sum*freq_sum + time_count_nonzero  + (1 | WorkerId_)\")\n",
    "    cv <- lme_cross_val(formula,aggregate_per_sentence[shuffled_order,], 'time_sum')\n",
    "    c(mean(cv-agg_baseline, na.rm=TRUE), var(cv-agg_baseline, na.rm=TRUE)/length(cv))\n",
    "}\n",
    "out <- cbind(labels, as.data.frame(do.call(rbind,lapply(powers_np_format, power_func))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "ynezLkhDGHPM",
    "outputId": "dd70f108-3d8d-424f-d411-f80993a45dd2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "ggplot(aes(x = labels, y = V1 ), data=out) + \n",
    "    geom_line() +\n",
    "    geom_point(size=5) +\n",
    "    geom_ribbon(aes(ymin=V1-sqrt(V2), ymax=V1+sqrt(V2)), alpha = 0.2, fill='red') +\n",
    "    ylab(\"Per Sentence ∆LogLik\") +\n",
    "    xlab(\"k\") +\n",
    "    ggtitle(\"Corpus\") +\n",
    "    theme_minimal() +\n",
    "    theme(text=element_text(size=25,family=\"serif\"))\n",
    "#ggsave('dundee.png', width = 8, height = 8, dpi=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acceptability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -i cola\n",
    "%R -i enwiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "d <- cola\n",
    "family <- binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "d <- enwiki\n",
    "family <- gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "set.seed(42)\n",
    "shuffled_order <- sample(nrow(d))\n",
    "lm_cross_val <- function(formula, df, d_var, family, num_folds=10, shuffle=FALSE){\n",
    "    if(shuffle){\n",
    "        df <- df[sample(nrow(df)),]\n",
    "    }\n",
    "    folds <- cut(seq(1,nrow(df)),breaks=num_folds,labels=FALSE)\n",
    "    estimates <- c()\n",
    "    for(i in 1:num_folds){\n",
    "        testIndexes <- which(folds==i,arr.ind=TRUE)\n",
    "        testData <- df[testIndexes,]\n",
    "        trainData <- df[-testIndexes,]\n",
    "        model <- glm(formula, data=trainData, family=family)\n",
    "        sigma <- mean(residuals(model)^2)\n",
    "        if(identical(binomial, family)){\n",
    "            predictions <- predict(model, newdata=testData, type=\"response\")\n",
    "        }else{\n",
    "            predictions <- predict(model, newdata=testData)\n",
    "        }\n",
    "        estimate <- log(dnorm(testData[[d_var]], \n",
    "                              mean=predictions, \n",
    "                              sd=sqrt(sigma)))\n",
    "        estimates <- c(estimates, estimate)\n",
    "    }\n",
    "    estimates\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "powers_np_format <- c('1.0', '1.25', '1.5' , '1.75', '2.0', '2.25', '2.5' , '2.75', '3.0','3.25', '3.5' , '3.75')\n",
    "powers <- seq(1, 3.75, by=0.25)\n",
    "baseline <- lm_cross_val(\"accept ~  len \", \n",
    "                          d[shuffled_order,], \n",
    "                         'accept', \n",
    "                        family)\n",
    "power_func <- function(x){\n",
    "        name <- paste0(\"log_prob_power_\",x,\":len\")\n",
    "        formula <- paste0(\"accept ~ \", name)\n",
    "        cv <- lm_cross_val(formula, d[shuffled_order,], 'accept', family)\n",
    "        c(mean(cv-baseline, na.rm=TRUE), var(cv-baseline, na.rm=TRUE)/length(cv),mean(cv, na.rm=TRUE))\n",
    "    }\n",
    "out <- cbind(powers, as.data.frame(do.call(rbind,lapply(powers_np_format, power_func))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "ggplot(aes(x = powers, y = V1 ), data=out) + \n",
    "    geom_line() +\n",
    "    geom_point(size=5) +\n",
    "    geom_ribbon(aes(ymin=V1-sqrt(V2), ymax=V1+sqrt(V2)), alpha = 0.2, fill='red') +\n",
    "    ylab(\"Per Sentence ∆LogLik\") +\n",
    "    xlab(\"k\") +\n",
    "    ggtitle(\"Cola Corpus\") +\n",
    "    theme_minimal() +\n",
    "    theme(text=element_text(size=25,family=\"serif\"))\n",
    "#ggsave('cola_pred_len_bs.png', width = 8, height = 8, dpi=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -i aggregate_per_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['mean','max','variance', 'variance_lang', 'ldiff', 'ldiff2', 'std']\n",
    "for i in POWER_RANGE:\n",
    "    attributes.extend(['entropy_'+str(i), 'entropy_n_'+str(i), 'power_'+str(i)])\n",
    "attributes = sorted(attributes)\n",
    "%R -i attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "set.seed(42)\n",
    "shuffled_order <- sample(nrow(aggregate_per_sentence))\n",
    "baseline <- lme_cross_val(\"time_sum ~   time_count_nonzero  + (1 | WorkerId_)\", \n",
    "                          aggregate_per_sentence[shuffled_order,],\n",
    "                         'time_sum')\n",
    "for(var in attributes){\n",
    "    predictor <- paste0(\"log_prob_\",var,\":len + time_count_nonzero\")\n",
    "    formula <- paste0(\"time_sum ~ \", predictor,\" + (1 | WorkerId_)\")\n",
    "    cat( mean(lme_cross_val(formula, aggregate_per_sentence[shuffled_order,], 'time_sum') - baseline, na.rm=TRUE)[[1]])\n",
    "    cat('\\n')\n",
    "\n",
    "}\n",
    "print('-------')\n",
    "##  baseline with perplexity predictor (log probs are in nats)\n",
    "baseline <- lme_cross_val(\"time_sum ~   I(exp(log_prob_mean)) + time_count_nonzero  + (1 | WorkerId_)\", \n",
    "                          aggregate_per_sentence[shuffled_order,],\n",
    "                         'time_sum')\n",
    "for(var in attributes){\n",
    "    predictor <- paste0(\"log_prob_\",var, \":len + I(exp(log_prob_mean)) + time_count_nonzero\")\n",
    "    formula <- paste0(\"time_sum ~ \", predictor,\" + (1 | WorkerId_)\")\n",
    "    tryCatch({\n",
    "        cat( mean(lme_cross_val(formula, aggregate_per_sentence[shuffled_order,], 'time_sum') - baseline, na.rm=TRUE)[[1]])\n",
    "        cat('\\n')\n",
    "        }, error = function(error_condition) {\n",
    "            print('-')\n",
    "        })\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "#print(r.squaredGLMM(model)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "baseline <- lm_cross_val(\"accept ~ len\", \n",
    "                          d[shuffled_order,], \n",
    "                         'accept', \n",
    "                        family)\n",
    "\n",
    "for(var in attributes){\n",
    "    predictor <- paste0(\"len:log_prob_\",var)\n",
    "    formula <- paste0(\"accept ~ \", predictor)\n",
    "    cat( mean(lm_cross_val(formula, d[shuffled_order,], 'accept', family) - baseline, na.rm=TRUE)[[1]])\n",
    "    cat('\\n')\n",
    "    \n",
    "}\n",
    "print(\"-----\")\n",
    "##  baseline with perplexity predictor (log probs are in nats)\n",
    "baseline <- lm_cross_val(\"accept ~ I(exp(log_prob_mean)) + len\", \n",
    "                          d[shuffled_order,], \n",
    "                         'accept', \n",
    "                        family)\n",
    "for(var in attributes){\n",
    "    predictor <- paste0(\"I(exp(log_prob_mean)) + len:log_prob_\",var)\n",
    "    formula <- paste0(\"accept ~ \", predictor)\n",
    "    cat( mean(lm_cross_val(formula, d[shuffled_order,], 'accept', family) - baseline, na.rm=TRUE)[[1]])\n",
    "    cat('\\n')\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6raxtnAIkGSH"
   },
   "outputs": [],
   "source": [
    "# Need to do this each time you switch data sets!\n",
    "%R -i data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "set.seed(42)\n",
    "shuffled_order <- sample(nrow(data))\n",
    "powers <- seq(1.0, 2.75, by=0.25)\n",
    "baseline <- lme_cross_val(\"time ~ freq*word_len + (1 | WorkerId)\", data[shuffled_order,], 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "out <- list()\n",
    "names <- c('log_prob', 'prev_log_prob', 'prev2_log_prob','prev3_log_prob')\n",
    "for(var in names){\n",
    "    other_vars <- paste(setdiff(names, var), collapse=\" + \")\n",
    "    cur_baseline <- lme_cross_val(paste0(\"time ~ \", other_vars, \" + freq*word_len + (1 | WorkerId)\"), data[shuffled_order,], 'time')\n",
    "    power_func <- function(x){\n",
    "        data$log_prob_pow <- data[[var]]**x\n",
    "        formula <- paste0(\"time ~ log_prob_pow +\", other_vars, \" + freq*word_len  + (1 | WorkerId)\")\n",
    "        cv <- lme_cross_val(formula, data[shuffled_order,], 'time')\n",
    "        diff <- cv-baseline\n",
    "        c(mean(diff, na.rm=TRUE), var(diff, na.rm=TRUE)/length(cv), mean(cv, na.rm=TRUE))\n",
    "    }\n",
    "    a <- do.call(rbind, lapply(powers, power_func))\n",
    "    out[[var]] <- cbind(powers, as.data.frame(a))\n",
    "}\n",
    "power_func <- function(x){\n",
    "        names <- c('log_prob', 'prev_log_prob', 'prev2_log_prob','prev3_log_prob')\n",
    "        for(var in names){\n",
    "            data[[paste0(var,'_pow')]] <- data[[var]]**x\n",
    "        }\n",
    "        formula <- paste0(\"time ~ log_prob_pow + prev_log_prob_pow + prev2_log_prob_pow +prev3_log_prob_pow + freq*word_len  + (1 | WorkerId)\")\n",
    "        cv <- lme_cross_val(formula, data[shuffled_order,], 'time')\n",
    "        diff <- cv-baseline\n",
    "        c(mean(diff, na.rm=TRUE), var(diff, na.rm=TRUE)/length(cv), mean(cv, na.rm=TRUE))\n",
    "    }\n",
    "a <- do.call(rbind, lapply(powers, power_func))\n",
    "out[['all_k']] <- cbind(powers, as.data.frame(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "var1<-'log_prob'\n",
    "var2<-'prev_log_prob'\n",
    "var3<-'prev2_log_prob'\n",
    "var4<-'prev3_log_prob'\n",
    "ggplot(aes(x = powers, y = V1),data=out[[var1]]) + \n",
    "    geom_line(aes(color='0')) +\n",
    "    geom_line(aes(color='-1'),data=out[[var2]]) +\n",
    "    geom_line(aes(color='-2'),data=out[[var3]]) +\n",
    "    geom_line(aes(color='-3'),data=out[[var4]]) +\n",
    "    geom_point(size=2) +\n",
    "    geom_point(data=out[[var2]], size=2) +\n",
    "    geom_point(data=out[[var3]], size=2) +\n",
    "    geom_point(data=out[[var4]], size=2) +\n",
    "    aes(ymin=V1-sqrt(V2), ymax=V1+sqrt(V2)) +\n",
    "    geom_ribbon(alpha = 0.2, fill='red') +\n",
    "    geom_ribbon(data=out[[var2]], alpha = 0.2, fill='purple') +\n",
    "    geom_ribbon(data=out[[var3]], alpha = 0.2, fill='blue') +\n",
    "    geom_ribbon(data=out[[var4]], alpha = 0.2, fill='darkgreen') +\n",
    "    scale_color_manual(name=\"Surprisal of Word at pos\", values= c(\"0\" = \"red\", \"-1\" = \"purple\", \"-2\" = \"blue\", \"-3\" = \"darkgreen\")) + \n",
    "    ylab(\"Per Token LogLik\") +\n",
    "    xlab(\"k\") +\n",
    "    ggtitle(\"Provo Corpus (with linear log-p predictors)\") +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['log_prob_power_' + str(i) for i in POWER_RANGE]\n",
    "r = enwiki.corr().accept[names]\n",
    "r_se = np.sqrt((1-r**2)/(len(enwiki) - 2))\n",
    "%R -i r\n",
    "%R -i r_se\n",
    "%R -i names\n",
    "%R -i power_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(ppcor)\n",
    "p_r <- c()\n",
    "p_r_se <- c()\n",
    "for(i in names){\n",
    "    test <- pcor.test(cola[['accept']], cola[[i]], cola[['len']])\n",
    "    p_r <- c(p_r, test$estimate)\n",
    "    p_r_se <- c(p_r_se, test$estimate/test$statistic)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "corrs <- as.data.frame(cbind(r=r,r_se=r_se,power_range))\n",
    "library(ggplot2)\n",
    "ggplot(aes(x = power_range, y = r ), data=corrs) + \n",
    "    geom_line() +\n",
    "    geom_point(size=5) +\n",
    "    geom_ribbon(aes(ymin=r-r_se, ymax=r+r_se), alpha = 0.2, fill='red') +\n",
    "    theme_minimal() +\n",
    "    labs(x = \"k\", y=\"Pearson's correlation coefficient\", title=\"CoLA\")+\n",
    "    theme(text=element_text(size=25,family=\"serif\")) +\n",
    "    scale_y_reverse()\n",
    "#ggsave('cola.png', width = 8, height = 8, dpi=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(tidyr)\n",
    "centered_df <- pivot_longer(data, c('log_prob','prev_log_prob','prev2_log_prob','prev3_log_prob'), names_to=\"pos\", values_to=\"log_prob\")\n",
    "ggplot(aes(x=log_prob, y=time, color=pos), data=centered_df) + \n",
    "    geom_smooth() +\n",
    "    labs(title=\"Corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cola['accept'] = cola['accept'].astype('category')plotnine.ggplot() + \\\n",
    "    plotnine.aes(x='log_prob_mean', y=\"..density..\", fill='accept') + \\\n",
    "    plotnine.geom_histogram(data=cola[cola['accept']=='1'], fill='blue', alpha = 0.5) +\\\n",
    "    plotnine.geom_histogram(data=cola[cola['accept']=='0'], fill='red', alpha = 0.5) +\\\n",
    "    plotnine.ylab(\"Density\") + \\\n",
    "    plotnine.xlab(\"Mean Sentence Surprisal\") + \\\n",
    "    plotnine.labels.ggtitle(\"CoLA corpus: blue = accept; red = reject\") + \\\n",
    "    plotnine.scale_fill_manual(values = {'acceptable':'blue', 'not acceptable': 'red'})\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "a3KD3WXU3l-O",
    "1r_n9OWV3l-Q",
    "JEA1ju653l-p",
    "q-EIELH43l_T"
   ],
   "name": "language_modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ede6d1e941341c59e0691f859271da3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "114a878aff67482a928ce41ed29ac028": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13cd18c98bf7491a9a27a7c3ef6aa4ae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15efe74b0da049eb93d66d84f10b3092": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "167e54144ee14de98628a2394e8e9b67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47ce7046050747ccb4dc3015677d11e8",
      "placeholder": "​",
      "style": "IPY_MODEL_662bdf8ab41647638c847dd063a9ad8c",
      "value": " 1.36M/1.36M [00:01&lt;00:00, 828kB/s]"
     }
    },
    "20b47415dfb34ab08ecbf7ea37619672": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4b5f1da26144b2fb2cb658986b38304",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ee8084f887d44a6a09c48c35e9e1e4d",
      "value": 1042301
     }
    },
    "297102f4a9a34e038d37313bbb6aace2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eb20e4e14a44cd8be52c7adffbb0086": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d33b55928d847498bfa37b57c9f7330",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f7ab2972ed74dd6b69a3d20f7b64901",
      "value": 665
     }
    },
    "360659bccda142909965ec6e5d6b0e2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2eb20e4e14a44cd8be52c7adffbb0086",
       "IPY_MODEL_60f907d4519047cc801eda211c19680e"
      ],
      "layout": "IPY_MODEL_114a878aff67482a928ce41ed29ac028"
     }
    },
    "3f7b744851d44d339f81911f9f123e5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66f6a68e1a98471595c64c64cb2184a6",
      "placeholder": "​",
      "style": "IPY_MODEL_5f16b8940b0741fd9e4b84d9574a46ec",
      "value": " 1.04M/1.04M [00:02&lt;00:00, 502kB/s]"
     }
    },
    "466c7761b8634e95999e234cdb31cd07": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "47ce7046050747ccb4dc3015677d11e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b2d902b773848b4a2be01bc3633b2f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eccca372ba574f24bf90f1019d19cdb9",
       "IPY_MODEL_6c35185ee9b24db7833393e2d83dce6e"
      ],
      "layout": "IPY_MODEL_b2cd7eb599be47158b068f28fd1b7294"
     }
    },
    "5ee8084f887d44a6a09c48c35e9e1e4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5f16b8940b0741fd9e4b84d9574a46ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60f907d4519047cc801eda211c19680e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8c95a40f2e04e6f8219f90062280e31",
      "placeholder": "​",
      "style": "IPY_MODEL_c126e7f5f5994baca78cfb6005363c03",
      "value": " 665/665 [00:20&lt;00:00, 32.0B/s]"
     }
    },
    "662bdf8ab41647638c847dd063a9ad8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66f6a68e1a98471595c64c64cb2184a6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c35185ee9b24db7833393e2d83dce6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88f1c33ee81849ba9000282b23b7efb6",
      "placeholder": "​",
      "style": "IPY_MODEL_8223cacfa0814690913d5936d34b8214",
      "value": " 548M/548M [00:20&lt;00:00, 26.8MB/s]"
     }
    },
    "6d33b55928d847498bfa37b57c9f7330": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80a0b1302cda41958c0da510d2bb0982": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ede6d1e941341c59e0691f859271da3",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_466c7761b8634e95999e234cdb31cd07",
      "value": 456318
     }
    },
    "8223cacfa0814690913d5936d34b8214": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "878f586819f94f1db5ee4e293a483a4c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "887ed81860494f85877ca0a4a669072e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88f1c33ee81849ba9000282b23b7efb6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e68b61b6e324991980ab64362a5b13b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "973d00e6981d45b8a419e063e66b634f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_878f586819f94f1db5ee4e293a483a4c",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c944a5aed5ff45a1974109645a6a2ca8",
      "value": 1355256
     }
    },
    "9ba6b8d763fd4f50912d973e4b28caf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80a0b1302cda41958c0da510d2bb0982",
       "IPY_MODEL_a8a13ec26f52454295d1ef8cd51154a2"
      ],
      "layout": "IPY_MODEL_297102f4a9a34e038d37313bbb6aace2"
     }
    },
    "9f7ab2972ed74dd6b69a3d20f7b64901": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a3c6e47cf0d9474aa7e9b83786d4c859": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_973d00e6981d45b8a419e063e66b634f",
       "IPY_MODEL_167e54144ee14de98628a2394e8e9b67"
      ],
      "layout": "IPY_MODEL_f1deda43831148c6a3fe176e4d658012"
     }
    },
    "a8a13ec26f52454295d1ef8cd51154a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4976f17821f47bb84efb356d51fe8cc",
      "placeholder": "​",
      "style": "IPY_MODEL_887ed81860494f85877ca0a4a669072e",
      "value": " 456k/456k [00:01&lt;00:00, 455kB/s]"
     }
    },
    "b2cd7eb599be47158b068f28fd1b7294": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c126e7f5f5994baca78cfb6005363c03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c944a5aed5ff45a1974109645a6a2ca8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d8c95a40f2e04e6f8219f90062280e31": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4b5f1da26144b2fb2cb658986b38304": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eccca372ba574f24bf90f1019d19cdb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15efe74b0da049eb93d66d84f10b3092",
      "max": 548118077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e68b61b6e324991980ab64362a5b13b",
      "value": 548118077
     }
    },
    "f1deda43831148c6a3fe176e4d658012": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f37c4b80c1ca4c46a7d4362d7472f275": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_20b47415dfb34ab08ecbf7ea37619672",
       "IPY_MODEL_3f7b744851d44d339f81911f9f123e5e"
      ],
      "layout": "IPY_MODEL_13cd18c98bf7491a9a27a7c3ef6aa4ae"
     }
    },
    "f4976f17821f47bb84efb356d51fe8cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
